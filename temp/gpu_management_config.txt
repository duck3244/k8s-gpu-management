# ============================================================================
# GPU Management Configuration Files
# ============================================================================

# application-gpu.yml - GPU 관리 전용 설정
---
spring:
  config:
    activate:
      on-profile: gpu-management

  # Oracle Database 설정
  datasource:
    url: jdbc:oracle:thin:@${DB_HOST:localhost}:${DB_PORT:1521}:${DB_SERVICE:ORCL}
    driver-class-name: oracle.jdbc.OracleDriver
    username: ${DB_USERNAME:gpu_admin}
    password: ${DB_PASSWORD:password}
    hikari:
      maximum-pool-size: 20
      minimum-idle: 10
      connection-timeout: 20000
      idle-timeout: 300000
      max-lifetime: 1200000
      pool-name: GpuManagementPool

  # JPA 설정
  jpa:
    database-platform: org.hibernate.dialect.Oracle12cDialect
    hibernate:
      ddl-auto: ${DDL_AUTO:validate}
      naming:
        physical-strategy: org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl
    show-sql: ${SHOW_SQL:false}
    properties:
      hibernate:
        format_sql: true
        use_sql_comments: true
        generate_statistics: true
        cache:
          use_second_level_cache: true
          region:
            factory_class: org.hibernate.cache.jcache.JCacheRegionFactory

# GPU 관리 전용 설정
gpu:
  management:
    enabled: true
    
    # 지원 GPU 모델 목록
    supported-models:
      - GTX1080
      - GTX1080TI
      - TITANXP
      - RTX2080
      - RTX2080TI
      - RTX3080
      - RTX3090
      - RTX4080
      - RTX4090
      - V100_16GB
      - V100_32GB
      - A100_40GB
      - A100_80GB
      - H100_80GB
    
    # MIG 관리 설정
    mig:
      enabled: true
      supported-models:
        - A100_40GB
        - A100_80GB
        - H100_80GB
      auto-cleanup: true
      cleanup-interval: "0 0 2 * * *" # 매일 새벽 2시
    
    # 메트릭 수집 설정
    metrics:
      collection-interval: 30s
      retention-days: 30
      batch-size: 100
      nvidia-smi:
        enabled: true
        path: "/usr/bin/nvidia-smi"
        timeout: 10s
      nvml:
        enabled: false
        library-path: "/usr/local/cuda/lib64/libnvidia-ml.so"
    
    # 할당 관리 설정
    allocation:
      auto-expire: true
      expire-check-interval: 5m
      default-duration-hours: 24
      max-duration-hours: 168 # 7일
      cost-tracking: true
      
    # 비용 계산 설정
    cost:
      enabled: true
      currency: "USD"
      default-rates:
        GTX1080: 0.5
        RTX4090: 2.0
        A100_80GB: 6.0
        H100_80GB: 8.0
      mig-discount: 0.7 # MIG 인스턴스는 30% 할인
    
    # 알람 설정
    alerts:
      enabled: true
      temperature-threshold: 85.0
      utilization-threshold: 90.0
      memory-threshold: 95.0
      power-threshold: 400.0
      notification:
        email:
          enabled: false
          recipients: []
        slack:
          enabled: false
          webhook-url: ""
        webhook:
          enabled: false
          url: ""
    
    # 최적화 설정
    optimization:
      enabled: true
      auto-optimization: false
      optimization-interval: "0 0 3 * * *" # 매일 새벽 3시
      strategies:
        - UNUSED_MIG_CLEANUP
        - OVERPROVISIONED_DETECTION
        - COST_OPTIMIZATION
        - WORKLOAD_BALANCING

# 로깅 설정
logging:
  level:
    com.k8s.monitor.service.gpu: DEBUG
    com.k8s.monitor.controller.gpu: DEBUG
    org.hibernate.SQL: ${SQL_LOG_LEVEL:WARN}
    org.hibernate.type.descriptor.sql.BasicBinder: ${SQL_BIND_LOG_LEVEL:WARN}
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level [GPU-MGMT] %logger{36} - %msg%n"

# 모니터링 설정
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus,gpu-health,gpu-metrics
  endpoint:
    gpu-health:
      enabled: true
    gpu-metrics:
      enabled: true
  metrics:
    tags:
      service: gpu-management
      cluster: ${CLUSTER_NAME:default}

---
# application-development.yml - 개발 환경 설정
spring:
  config:
    activate:
      on-profile: development

  # H2 데이터베이스 (개발용)
  datasource:
    url: jdbc:h2:mem:gpu_management_dev
    driver-class-name: org.h2.Driver
    username: sa
    password: password

  jpa:
    hibernate:
      ddl-auto: create-drop
    show-sql: true

  h2:
    console:
      enabled: true
      path: /h2-console

gpu:
  management:
    metrics:
      collection-interval: 10s
      nvidia-smi:
        enabled: false # 개발 환경에서는 모의 데이터 사용
    allocation:
      default-duration-hours: 1 # 개발 환경에서는 짧은 기간

logging:
  level:
    com.k8s.monitor: DEBUG
    org.hibernate.SQL: DEBUG

---
# application-production.yml - 운영 환경 설정
spring:
  config:
    activate:
      on-profile: production

  datasource:
    hikari:
      maximum-pool-size: 50
      minimum-idle: 20

gpu:
  management:
    metrics:
      collection-interval: 30s
      retention-days: 90
      batch-size: 500
    allocation:
      auto-expire: true
      default-duration-hours: 24
    alerts:
      enabled: true
      notification:
        email:
          enabled: true
          recipients:
            - gpu-admin@company.com
            - ops-team@company.com
        slack:
          enabled: true
          webhook-url: "${SLACK_WEBHOOK_URL}"

logging:
  level:
    root: WARN
    com.k8s.monitor: INFO
  file:
    name: /var/log/k8s-monitor/gpu-management.log

---
# Kubernetes Deployment YAML
apiVersion: apps/v1
kind: Deployment
metadata:
  name: k8s-gpu-monitor
  namespace: k8s-monitoring
  labels:
    app: k8s-gpu-monitor
    component: gpu-management
spec:
  replicas: 2
  selector:
    matchLabels:
      app: k8s-gpu-monitor
  template:
    metadata:
      labels:
        app: k8s-gpu-monitor
    spec:
      serviceAccountName: gpu-monitor
      containers:
      - name: gpu-monitor
        image: k8s-gpu-monitor:latest
        ports:
        - containerPort: 8080
          name: http
        - containerPort: 8081
          name: management
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "production,gpu-management"
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: gpu-db-secret
              key: host
        - name: DB_USERNAME
          valueFrom:
            secretKeyRef:
              name: gpu-db-secret
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: gpu-db-secret
              key: password
        - name: CLUSTER_NAME
          value: "production-cluster"
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /actuator/health
            port: 8081
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8081
          initialDelaySeconds: 30
          periodSeconds: 10
        volumeMounts:
        - name: config
          mountPath: /app/config
        - name: logs
          mountPath: /var/log/k8s-monitor
      volumes:
      - name: config
        configMap:
          name: gpu-monitor-config
      - name: logs
        emptyDir: {}

---
apiVersion: v1
kind: Service
metadata:
  name: k8s-gpu-monitor
  namespace: k8s-monitoring
  labels:
    app: k8s-gpu-monitor
spec:
  selector:
    app: k8s-gpu-monitor
  ports:
  - name: http
    port: 80
    targetPort: 8080
  - name: management
    port: 8081
    targetPort: 8081

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: gpu-monitor
  namespace: k8s-monitoring

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: gpu-monitor
rules:
- apiGroups: [""]
  resources: ["nodes", "pods"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["metrics.k8s.io"]
  resources: ["nodes", "pods"]
  verbs: ["get", "list"]
- apiGroups: ["apps"]
  resources: ["deployments", "replicasets"]
  verbs: ["get", "list", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: gpu-monitor
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: gpu-monitor
subjects:
- kind: ServiceAccount
  name: gpu-monitor
  namespace: k8s-monitoring

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: gpu-monitor-config
  namespace: k8s-monitoring
data:
  application.yml: |
    server:
      port: 8080
    management:
      server:
        port: 8081
    
    spring:
      profiles:
        active: production,gpu-management

---
apiVersion: v1
kind: Secret
metadata:
  name: gpu-db-secret
  namespace: k8s-monitoring
type: Opaque
data:
  host: b3JhY2xlLWRiLnNlcnZpY2Uuc3ZjLmNsdXN0ZXIubG9jYWw= # oracle-db.service.svc.cluster.local
  username: Z3B1X2FkbWlu # gpu_admin
  password: cGFzc3dvcmQ= # password

---
# GPU 메트릭 수집을 위한 DaemonSet
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: gpu-metrics-collector
  namespace: k8s-monitoring
  labels:
    app: gpu-metrics-collector
spec:
  selector:
    matchLabels:
      app: gpu-metrics-collector
  template:
    metadata:
      labels:
        app: gpu-metrics-collector
    spec:
      hostPID: true
      hostIPC: true
      containers:
      - name: gpu-collector
        image: nvidia/cuda:11.8-runtime-ubuntu20.04
        command: ["/bin/sh"]
        args:
        - -c
        - |
          while true; do
            if command -v nvidia-smi >/dev/null 2>&1; then
              nvidia-smi --query-gpu=index,name,uuid,temperature.gpu,power.draw,utilization.gpu,memory.used,memory.total --format=csv,noheader,nounits > /shared/gpu-metrics.csv
              curl -X POST http://k8s-gpu-monitor/api/v1/gpu/metrics/collect || true
            fi
            sleep 30
          done
        securityContext:
          privileged: true
        volumeMounts:
        - name: shared-data
          mountPath: /shared
        - name: dev
          mountPath: /dev
        resources:
          limits:
            nvidia.com/gpu: 0 # 메트릭 수집만 하므로 GPU 할당 불필요
      volumes:
      - name: shared-data
        hostPath:
          path: /tmp/gpu-metrics
      - name: dev
        hostPath:
          path: /dev
      nodeSelector:
        accelerator: nvidia-gpu
      tolerations:
      - operator: Exists

---
# Prometheus ServiceMonitor for GPU metrics
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: gpu-monitor
  namespace: k8s-monitoring
  labels:
    app: k8s-gpu-monitor
spec:
  selector:
    matchLabels:
      app: k8s-gpu-monitor
  endpoints:
  - port: management
    path: /actuator/prometheus
    interval: 30s