# K8s GPU Management ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

ì´ ë¬¸ì„œëŠ” Kubernetes GPU ê´€ë¦¬ ì‹œìŠ¤í…œì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì¼ë°˜ì ì¸ ë¬¸ì œë“¤ê³¼ í•´ê²° ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨
- [GPU ì¥ë¹„ ê´€ë ¨ ë¬¸ì œ](#gpu-ì¥ë¹„-ê´€ë ¨-ë¬¸ì œ)
- [MIG ê´€ë¦¬ ë¬¸ì œ](#mig-ê´€ë¦¬-ë¬¸ì œ)
- [í• ë‹¹ ë° ìŠ¤ì¼€ì¤„ë§ ë¬¸ì œ](#í• ë‹¹-ë°-ìŠ¤ì¼€ì¤„ë§-ë¬¸ì œ)
- [ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë¬¸ì œ](#ë©”íŠ¸ë¦­-ìˆ˜ì§‘-ë¬¸ì œ)
- [ì„±ëŠ¥ ê´€ë ¨ ë¬¸ì œ](#ì„±ëŠ¥-ê´€ë ¨-ë¬¸ì œ)
- [ë„¤íŠ¸ì›Œí‚¹ ë¬¸ì œ](#ë„¤íŠ¸ì›Œí‚¹-ë¬¸ì œ)
- [ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¬¸ì œ](#ë°ì´í„°ë² ì´ìŠ¤-ì—°ê²°-ë¬¸ì œ)
- [ë³´ì•ˆ ë° ê¶Œí•œ ë¬¸ì œ](#ë³´ì•ˆ-ë°-ê¶Œí•œ-ë¬¸ì œ)

---

## GPU ì¥ë¹„ ê´€ë ¨ ë¬¸ì œ

### ğŸ”¥ ë¬¸ì œ: GPU ê³¼ì—´ (Temperature > 85Â°C)

#### ì¦ìƒ
- GPU ì˜¨ë„ê°€ 85Â°C ì´ìƒìœ¼ë¡œ ì§€ì†ë¨
- ì„±ëŠ¥ ì €í•˜ ë˜ëŠ” thermal throttling ë°œìƒ
- ì‹œìŠ¤í…œ ë¶ˆì•ˆì •ì„±

#### ì§„ë‹¨ ë°©ë²•
```bash
# GPU ì˜¨ë„ í™•ì¸
nvidia-smi --query-gpu=temperature.gpu,temperature.memory --format=csv

# ì‹œìŠ¤í…œ ë¡œê·¸ í™•ì¸
journalctl -u nvidia-persistenced -f

# GPU ë©”íŠ¸ë¦­ ì¡°íšŒ
curl -s http://localhost:8080/k8s-monitor/api/v1/gpu/devices/{device-id}/health
```

#### í•´ê²° ë°©ë²•
1. **ì¦‰ì‹œ ì¡°ì¹˜**
   ```bash
   # ì›Œí¬ë¡œë“œ ì¼ì‹œ ì¤‘ë‹¨
   kubectl scale deployment gpu-workload --replicas=0
   
   # GPU ì „ë ¥ ì œí•œ ì„¤ì •
   sudo nvidia-smi -pl 300  # 300Wë¡œ ì œí•œ
   ```

2. **ê·¼ë³¸ ì›ì¸ í•´ê²°**
   ```bash
   # íŒ¬ ì†ë„ í™•ì¸ ë° ì¡°ì •
   nvidia-smi --query-gpu=fan.speed --format=csv
   
   # ëƒ‰ê° ì‹œìŠ¤í…œ ì ê²€
   sudo sensors
   
   # ë°ì´í„°ì„¼í„° í™˜ê²½ ì˜¨ë„ í™•ì¸
   ```

3. **ì˜ˆë°© ì¡°ì¹˜**
   - ì •ê¸°ì ì¸ í•˜ë“œì›¨ì–´ ì ê²€
   - ëƒ‰ê° ì‹œìŠ¤í…œ ìœ ì§€ë³´ìˆ˜
   - í™˜ê²½ ëª¨ë‹ˆí„°ë§ ê°•í™”

---

### âš¡ ë¬¸ì œ: GPU ì „ë ¥ ì†Œëª¨ ì´ìƒ

#### ì¦ìƒ
- ì˜ˆìƒë³´ë‹¤ ë†’ì€ ì „ë ¥ ì†Œëª¨
- ì „ë ¥ ê³µê¸‰ ì¥ì¹˜ ê³¼ë¶€í•˜
- ì‹œìŠ¤í…œ ì¬ì‹œì‘ ë˜ëŠ” ì „ì› ì°¨ë‹¨

#### ì§„ë‹¨ ë°©ë²•
```bash
# ì „ë ¥ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
nvidia-smi --query-gpu=power.draw,power.limit --format=csv,noheader,nounits

# ì‹œê°„ë³„ ì „ë ¥ ì†Œëª¨ ì¶”ì„¸ í™•ì¸
curl -s "http://localhost:8080/k8s-monitor/api/v1/gpu/metrics/data?hours=24&deviceId={device-id}"

# ì „ë ¥ ê³µê¸‰ ì¥ì¹˜ ìƒíƒœ í™•ì¸
sudo dmidecode -t 39
```

#### í•´ê²° ë°©ë²•
1. **ì¦‰ì‹œ ì „ë ¥ ì œí•œ**
   ```bash
   # ì „ë ¥ í•œë„ ì„¤ì •
   sudo nvidia-smi -pl 250  # 250Wë¡œ ì œí•œ
   
   # í´ëŸ­ ì†ë„ ì œí•œ
   sudo nvidia-smi -lgc 1200  # Graphics clockì„ 1200MHzë¡œ ì œí•œ
   ```

2. **ì›Œí¬ë¡œë“œ ë¶„ì‚°**
   ```bash
   # ë‹¤ë¥¸ ë…¸ë“œë¡œ ì›Œí¬ë¡œë“œ ì´ë™
   kubectl drain {node-name} --ignore-daemonsets
   kubectl uncordon {other-node-name}
   ```

---

### ğŸš« ë¬¸ì œ: GPU ì¸ì‹ ë¶ˆê°€

#### ì¦ìƒ
- `nvidia-smi` ëª…ë ¹ì–´ ì‹¤íŒ¨
- Kubernetesì—ì„œ GPU ë¦¬ì†ŒìŠ¤ ì¸ì‹ ì•ˆë¨
- ë“œë¼ì´ë²„ ì˜¤ë¥˜ ë©”ì‹œì§€

#### ì§„ë‹¨ ë°©ë²•
```bash
# GPU í•˜ë“œì›¨ì–´ ì¸ì‹ í™•ì¸
lspci | grep -i nvidia

# ë“œë¼ì´ë²„ ìƒíƒœ í™•ì¸
nvidia-smi
modinfo nvidia

# Kubernetes GPU í”ŒëŸ¬ê·¸ì¸ ìƒíƒœ
kubectl get nodes -o yaml | grep nvidia.com/gpu

# ì‹œìŠ¤í…œ ë¡œê·¸ í™•ì¸
dmesg | grep -i nvidia
journalctl -u nvidia-persistenced
```

#### í•´ê²° ë°©ë²•
1. **ë“œë¼ì´ë²„ ì¬ì„¤ì¹˜**
   ```bash
   # ê¸°ì¡´ ë“œë¼ì´ë²„ ì œê±°
   sudo apt-get purge nvidia-*
   
   # ìµœì‹  ë“œë¼ì´ë²„ ì„¤ì¹˜
   sudo apt update
   sudo apt install nvidia-driver-535
   
   # ì‹œìŠ¤í…œ ì¬ì‹œì‘
   sudo reboot
   ```

2. **NVIDIA Container Toolkit ì¬ì„¤ì •**
   ```bash
   # Container Toolkit ì¬ì„¤ì¹˜
   sudo apt-get update
   sudo apt-get install -y nvidia-container-toolkit
   
   # Docker ì¬ì‹œì‘
   sudo systemctl restart docker
   ```

3. **Kubernetes GPU Operator ì¬ë°°í¬**
   ```bash
   # GPU Operator ì‚­ì œ
   kubectl delete -f https://raw.githubusercontent.com/NVIDIA/gpu-operator/main/deployments/gpu-operator/gpu-operator.yaml
   
   # ì¬ë°°í¬
   kubectl apply -f https://raw.githubusercontent.com/NVIDIA/gpu-operator/main/deployments/gpu-operator/gpu-operator.yaml
   ```

---

## MIG ê´€ë¦¬ ë¬¸ì œ

### ğŸ”§ ë¬¸ì œ: MIG ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨

#### ì¦ìƒ
- MIG ì¸ìŠ¤í„´ìŠ¤ ìƒì„± API í˜¸ì¶œ ì‹¤íŒ¨
- "MIG not supported" ì˜¤ë¥˜ ë©”ì‹œì§€
- GPUê°€ MIG ëª¨ë“œë¡œ ì „í™˜ë˜ì§€ ì•ŠìŒ

#### ì§„ë‹¨ ë°©ë²•
```bash
# GPU MIG ì§€ì› ì—¬ë¶€ í™•ì¸
nvidia-smi --query-gpu=name,mig.mode.current,mig.mode.pending --format=csv

# MIG ì¸ìŠ¤í„´ìŠ¤ í˜„ì¬ ìƒíƒœ
nvidia-smi mig -lgip

# ì§€ì›ë˜ëŠ” MIG í”„ë¡œí•„ í™•ì¸
nvidia-smi mig -lgip -i 0

# ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸ í™•ì¸
kubectl logs -f deployment/k8s-gpu-monitor | grep -i mig
```

#### í•´ê²° ë°©ë²•
1. **MIG ëª¨ë“œ í™œì„±í™”**
   ```bash
   # MIG ëª¨ë“œ í™œì„±í™”
   sudo nvidia-smi -mig 1
   
   # ì‹œìŠ¤í…œ ì¬ì‹œì‘ (í•„ìš”í•œ ê²½ìš°)
   sudo reboot
   
   # MIG ëª¨ë“œ í™•ì¸
   nvidia-smi --query-gpu=mig.mode.current --format=csv
   ```

2. **GPU ëª¨ë¸ í˜¸í™˜ì„± í™•ì¸**
   ```bash
   # MIG ì§€ì› GPU í™•ì¸ (A100, A30, H100 ë“±)
   nvidia-smi --query-gpu=name --format=csv
   
   # ë“œë¼ì´ë²„ ë²„ì „ í™•ì¸ (450.80.02 ì´ìƒ í•„ìš”)
   nvidia-smi --query-gpu=driver_version --format=csv
   ```

3. **ê¶Œí•œ ë¬¸ì œ í•´ê²°**
   ```bash
   # nvidia-ml ê¶Œí•œ í™•ì¸
   ls -la /dev/nvidia*
   
   # í•„ìš”ì‹œ ê¶Œí•œ ìˆ˜ì •
   sudo chmod 666 /dev/nvidia*
   ```

---

### ğŸ¯ ë¬¸ì œ: MIG ì¸ìŠ¤í„´ìŠ¤ í• ë‹¹ ì‹¤íŒ¨

#### ì¦ìƒ
- MIG ì¸ìŠ¤í„´ìŠ¤ê°€ ìˆì§€ë§Œ í• ë‹¹ë˜ì§€ ì•ŠìŒ
- "No suitable MIG instance available" ì˜¤ë¥˜
- Podê°€ Pending ìƒíƒœë¡œ ë‚¨ì•„ìˆìŒ

#### ì§„ë‹¨ ë°©ë²•
```bash
# ì‚¬ìš© ê°€ëŠ¥í•œ MIG ì¸ìŠ¤í„´ìŠ¤ í™•ì¸
curl -s http://localhost:8080/k8s-monitor/api/v1/gpu/mig/available

# MIG ì¸ìŠ¤í„´ìŠ¤ ì„¸ë¶€ ì •ë³´
nvidia-smi mig -lgi

# Pod ì´ë²¤íŠ¸ í™•ì¸
kubectl describe pod {pod-name}

# GPU í• ë‹¹ ìš”ì²­ í™•ì¸
curl -s http://localhost:8080/k8s-monitor/api/v1/gpu/allocations
```

#### í•´ê²° ë°©ë²•
1. **MIG ì¸ìŠ¤í„´ìŠ¤ ìƒíƒœ ë³µêµ¬**
   ```bash
   # ëª¨ë“  MIG ì¸ìŠ¤í„´ìŠ¤ ì‚­ì œ í›„ ì¬ìƒì„±
   sudo nvidia-smi mig -dci
   sudo nvidia-smi mig -dgi
   
   # ìƒˆë¡œìš´ MIG ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
   sudo nvidia-smi mig -cgi 19,14,9  # 1g.10gb, 2g.20gb, 3g.40gb í”„ë¡œí•„
   sudo nvidia-smi mig -cci -gi 0
   ```

2. **í• ë‹¹ ìš”ì²­ ìš”êµ¬ì‚¬í•­ í™•ì¸**
   ```bash
   # ìš”ì²­ëœ ë©”ëª¨ë¦¬ í¬ê¸°ì™€ ì‚¬ìš© ê°€ëŠ¥í•œ MIG í”„ë¡œí•„ ë¹„êµ
   curl -s http://localhost:8080/k8s-monitor/api/v1/gpu/mig/profiles | \
     jq '.data[] | {profileName, memoryGb, maxInstancesPerGpu}'
   ```

3. **ìˆ˜ë™ìœ¼ë¡œ ì ì ˆí•œ MIG ì¸ìŠ¤í„´ìŠ¤ í• ë‹¹**
   ```bash
   # íŠ¹ì • í”„ë¡œí•„ì˜ MIG ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
   curl -X POST http://localhost:8080/k8s-monitor/api/v1/gpu/mig/devices/gpu-worker-1-GPU-00 \
     -H "Content-Type: application/json" \
     -d '{"profileIds": ["1g.10gb"]}'
   ```

---

## í• ë‹¹ ë° ìŠ¤ì¼€ì¤„ë§ ë¬¸ì œ

### ğŸ’¼ ë¬¸ì œ: GPU í• ë‹¹ ëŒ€ê¸°ì—´ ì¦ê°€

#### ì¦ìƒ
- í• ë‹¹ ìš”ì²­ì´ ëŒ€ê¸°ì—´ì—ì„œ ì²˜ë¦¬ë˜ì§€ ì•ŠìŒ
- "No available GPU" ë©”ì‹œì§€ ì§€ì†
- Podê°€ Pending ìƒíƒœë¡œ ìœ ì§€ë¨

#### ì§„ë‹¨ ë°©ë²•
```bash
# ëŒ€ê¸° ì¤‘ì¸ í• ë‹¹ ìš”ì²­ í™•ì¸
curl -s http://localhost:8080/k8s-monitor/api/v1/gpu/allocations | \
  jq '.data[] | select(.status == "PENDING")'

# ì‚¬ìš© ê°€ëŠ¥í•œ GPU ë¦¬ì†ŒìŠ¤ í™•ì¸
curl -s http://localhost:8080/k8s-monitor/api/v1/gpu/devices?status=available

# í´ëŸ¬ìŠ¤í„° ìš©ëŸ‰ ë¶„ì„
curl -s http://localhost:8080/k8s-monitor/api/v1/gpu/overview
```

#### í•´ê²° ë°©ë²•
1. **ë§Œë£Œëœ í• ë‹¹ ì •ë¦¬**
   ```bash
   # ë§Œë£Œëœ í• ë‹¹ ìë™ ì •ë¦¬
   curl -X POST http://localhost:8080/k8s-monitor/api/v1/gpu/allocations/cleanup
   
   # íŠ¹ì • í• ë‹¹ ìˆ˜ë™ í•´ì œ
   curl -X DELETE http://localhost:8080/k8s-monitor/api/v1/gpu/allocations/ALLOC-ABC12345
   ```

2. **ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ìŠ¤ì¼€ì¤„ë§**
   ```bash
   # ë†’ì€ ìš°ì„ ìˆœìœ„ í• ë‹¹ ìƒì„±
   curl -X POST http://localhost:8080/k8s-monitor/api/v1/gpu/allocations \
     -H "Content-Type: application/json" \
     -d '{
       "namespace": "critical-workload",
       "podName": "urgent-task",
       "priorityClass": "high",
       "workloadType": "Training"
     }'
   ```

---

### ğŸ• ë¬¸ì œ: í• ë‹¹ ì‹œê°„ ì´ˆê³¼

#### ì¦ìƒ
- í• ë‹¹ì´ ê³„íšëœ ì‹œê°„ì„ ì´ˆê³¼í•˜ì—¬ ì§€ì†ë¨
- ìë™ í•´ì œê°€ ì‘ë™í•˜ì§€ ì•ŠìŒ
- ë¦¬ì†ŒìŠ¤ê°€ ë°˜í™˜ë˜ì§€ ì•ŠìŒ

#### ì§„ë‹¨ ë°©ë²•
```bash
# ë§Œë£Œ ì˜ˆì • í• ë‹¹ í™•ì¸
curl -s http://localhost:8080/k8s-monitor/api/v1/gpu/allocations/expiring?hours=0

# ì¥ê¸° ì‹¤í–‰ í• ë‹¹ í™•ì¸
curl -s http://localhost:8080/k8s-monitor/api/v1/gpu/allocations | \
  jq '.data[] | select(.status == "ALLOCATED" and (.allocationTime | fromdateiso8601) < (now - 86400))'
```

#### í•´ê²° ë°©ë²•
1. **ìë™ ë§Œë£Œ ë©”ì»¤ë‹ˆì¦˜ í™•ì¸**
   ```bash
   # ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ í™•ì¸
   kubectl logs deployment/k8s-gpu-management -n gpu-management | grep "autoExpireAllocations"
   
   # ìˆ˜ë™ìœ¼ë¡œ ë§Œë£Œ ì‘ì—… ì‹¤í–‰
   curl -X POST http://localhost:8080/k8s-monitor/api/v1/gpu/allocations/expire-old
   ```

2. **í• ë‹¹ ì—°ì¥**
   ```bash
   # í• ë‹¹ ì‹œê°„ ì—°ì¥
   curl -X PUT http://localhost:8080/k8s-monitor/api/v1/gpu/allocations/ALLOC-ABC12345/extend \
     -H "Content-Type: application/json" \
     -d '{"additionalHours": 24}'
   ```

---

## ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë¬¸ì œ

### ğŸ“Š ë¬¸ì œ: ë©”íŠ¸ë¦­ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ë‹¨

#### ì¦ìƒ
- Prometheusì—ì„œ GPU ë©”íŠ¸ë¦­ì´ ì‚¬ë¼ì§
- ê·¸ë¼íŒŒë‚˜ ëŒ€ì‹œë³´ë“œì— ë°ì´í„° ì—†ìŒ
- "No data" ë©”ì‹œì§€

#### ì§„ë‹¨ ë°©ë²•
```bash
# ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ìƒíƒœ í™•ì¸
curl -s http://localhost:8080/k8s-monitor/api/v1/gpu/metrics/collection-status

# ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸ ì§ì ‘ í™•ì¸
curl -s http://localhost:8080/k8s-monitor/actuator/prometheus | grep gpu

# DCGM Exporter ìƒíƒœ í™•ì¸
kubectl get pods -l app=dcgm-exporter -n gpu-system
kubectl logs daemonset/dcgm-exporter -n gpu-system
```

#### í•´ê²° ë°©ë²•
1. **ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì¬ì‹œì‘**
   ```bash
   # GPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì„œë¹„ìŠ¤ ì¬ì‹œì‘
   kubectl rollout restart deployment/k8s-gpu-management -n gpu-management
   
   # DCGM Exporter ì¬ì‹œì‘
   kubectl rollout restart daemonset/dcgm-exporter -n gpu-system
   ```

2. **ìˆ˜ë™ ë©”íŠ¸ë¦­ ìˆ˜ì§‘**
   ```bash
   # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ê°•ì œ ì‹¤í–‰
   curl -X POST http://localhost:8080/k8s-monitor/api/v1/gpu/metrics/collect
   
   # ì»¬ë ‰ì…˜ ì¬ì‹œì‘
   curl -X POST http://localhost:8080/k8s-monitor/api/v1/gpu/metrics/collection/restart
   ```

---

### ğŸ” ë¬¸ì œ: nvidia-smi ëª…ë ¹ì–´ ì‹¤í–‰ ì‹¤íŒ¨

#### ì¦ìƒ
- "nvidia-smi: command not found" ì˜¤ë¥˜
- GPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨
- ë“œë¼ì´ë²„ ê´€ë ¨ ì˜¤ë¥˜

#### ì§„ë‹¨ ë°©ë²•
```bash
# ë…¸ë“œì—ì„œ NVIDIA ë“œë¼ì´ë²„ í™•ì¸
kubectl debug node/gpu-worker-1 -it --image=nvidia/cuda:11.8-devel-ubuntu20.04
# ì»¨í…Œì´ë„ˆ ë‚´ì—ì„œ:
nvidia-smi
ls -la /usr/bin/nvidia-smi

# GPU ë””ë°”ì´ìŠ¤ íŒŒì¼ í™•ì¸
ls -la /dev/nvidia*

# ë“œë¼ì´ë²„ ëª¨ë“ˆ í™•ì¸
lsmod | grep nvidia
```

#### í•´ê²° ë°©ë²•
1. **NVIDIA ë“œë¼ì´ë²„ ì¬ì„¤ì¹˜**
   ```bash
   # ê¸°ì¡´ ë“œë¼ì´ë²„ ì œê±°
   sudo apt-get purge nvidia-*
   sudo apt-get autoremove
   
   # ìµœì‹  ë“œë¼ì´ë²„ ì„¤ì¹˜
   sudo apt update
   sudo apt install nvidia-driver-535
   sudo reboot
   ```

2. **NVIDIA Container Toolkit ì¬ì„¤ì •**
   ```bash
   # Container Toolkit ì¬ì„¤ì¹˜
   curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
   
   echo "deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://nvidia.github.io/libnvidia-container/stable/deb/$(ARCH) /" | \
     sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
   
   sudo apt update
   sudo apt install -y nvidia-container-toolkit
   sudo nvidia-ctk runtime configure --runtime=docker
   sudo systemctl restart docker
   ```

---

## ì„±ëŠ¥ ê´€ë ¨ ë¬¸ì œ

### ğŸŒ ë¬¸ì œ: API ì‘ë‹µ ì‹œê°„ ì§€ì—°

#### ì¦ìƒ
- API í˜¸ì¶œì´ 5ì´ˆ ì´ìƒ ì†Œìš”
- íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜ ë°œìƒ
- ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ì‘ë‹µ ì§€ì—°

#### ì§„ë‹¨ ë°©ë²•
```bash
# JVM ë©”íŠ¸ë¦­ í™•ì¸
curl -s http://localhost:8080/k8s-monitor/actuator/metrics/jvm.memory.used
curl -s http://localhost:8080/k8s-monitor/actuator/metrics/jvm.gc.pause

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ìƒíƒœ
curl -s http://localhost:8080/k8s-monitor/actuator/metrics/hikaricp.connections.active

# HTTP ìš”ì²­ ë©”íŠ¸ë¦­
curl -s http://localhost:8080/k8s-monitor/actuator/prometheus | grep http_server_requests
```

#### í•´ê²° ë°©ë²•
1. **JVM ë©”ëª¨ë¦¬ ìµœì í™”**
   ```yaml
   # Deploymentì—ì„œ JVM ì˜µì…˜ ì¡°ì •
   env:
   - name: JAVA_OPTS
     value: |
       -Xms4g -Xmx8g
       -XX:+UseG1GC
       -XX:MaxGCPauseMillis=200
       -XX:+UseStringDeduplication
       -XX:+OptimizeStringConcat
   ```

2. **ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™”**
   ```sql
   -- ìì£¼ ì‚¬ìš©ë˜ëŠ” ì¿¼ë¦¬ì— ì¸ë±ìŠ¤ ì¶”ê°€
   CREATE INDEX idx_gpu_metrics_device_timestamp 
   ON gpu_usage_metrics(device_id, timestamp);
   
   CREATE INDEX idx_allocations_status_time 
   ON gpu_allocations(status, allocation_time);
   
   -- í†µê³„ ì •ë³´ ì—…ë°ì´íŠ¸
   EXEC DBMS_STATS.GATHER_SCHEMA_STATS('GPU_ADMIN');
   ```

3. **ìºì‹± í™œì„±í™”**
   ```yaml
   spring:
     cache:
       type: caffeine
       caffeine:
         spec: maximumSize=1000,expireAfterWrite=10m
   ```

---

### ğŸ’¾ ë¬¸ì œ: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³¼ë‹¤

#### ì¦ìƒ
- OutOfMemoryError ë°œìƒ
- Pod ì¬ì‹œì‘ ë°˜ë³µ
- GC ì‹œê°„ ê³¼ë‹¤

#### ì§„ë‹¨ ë°©ë²•
```bash
# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
kubectl top pod k8s-gpu-management-xxx -n gpu-management

# JVM ë©”ëª¨ë¦¬ ìƒì„¸ ì •ë³´
curl -s http://localhost:8080/k8s-monitor/actuator/metrics/jvm.memory.used | jq
curl -s http://localhost:8080/k8s-monitor/actuator/metrics/jvm.memory.max | jq

# GC ë©”íŠ¸ë¦­ í™•ì¸
curl -s http://localhost:8080/k8s-monitor/actuator/metrics/jvm.gc.pause | jq
```

#### í•´ê²° ë°©ë²•
1. **ë©”ëª¨ë¦¬ ë¦¬ì†ŒìŠ¤ ì¦ê°€**
   ```yaml
   resources:
     limits:
       memory: "8Gi"  # 4Giì—ì„œ 8Gië¡œ ì¦ê°€
     requests:
       memory: "4Gi"  # 2Giì—ì„œ 4Gië¡œ ì¦ê°€
   ```

2. **ë©”ëª¨ë¦¬ ë¦¬í¬ ë°©ì§€**
   ```java
   // ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ë°°ì¹˜ í¬ê¸° ì œí•œ
   @Value("${gpu.management.metrics.batch-size:100}")
   private int batchSize;
   
   // ì˜¤ë˜ëœ ë©”íŠ¸ë¦­ ë°ì´í„° ì •ë¦¬
   @Scheduled(cron = "0 0 2 * * *")
   public void cleanupOldMetrics() {
       LocalDateTime cutoff = LocalDateTime.now().minusDays(7);
       metricsRepository.deleteOldMetrics(cutoff);
   }
   ```

---

## ë„¤íŠ¸ì›Œí‚¹ ë¬¸ì œ

### ğŸŒ ë¬¸ì œ: ì„œë¹„ìŠ¤ ê°„ í†µì‹  ì‹¤íŒ¨

#### ì¦ìƒ
- 503 Service Unavailable ì˜¤ë¥˜
- ì—°ê²° ê±°ë¶€ (Connection refused)
- DNS í•´ì„ ì‹¤íŒ¨

#### ì§„ë‹¨ ë°©ë²•
```bash
# ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬ í™•ì¸
kubectl get svc,ep -n gpu-management

# DNS í•´ì„ í…ŒìŠ¤íŠ¸
kubectl exec -it deployment/k8s-gpu-management -n gpu-management -- \
  nslookup oracle-db.default.svc.cluster.local

# ë„¤íŠ¸ì›Œí¬ ì—°ê²° í…ŒìŠ¤íŠ¸
kubectl exec -it deployment/k8s-gpu-management -n gpu-management -- \
  nc -zv oracle-db.default.svc.cluster.local 1521
```

#### í•´ê²° ë°©ë²•
1. **ì„œë¹„ìŠ¤ ì„¤ì • í™•ì¸**
   ```yaml
   # ì„œë¹„ìŠ¤ ë¼ë²¨ ì…€ë ‰í„° ê²€ì¦
   apiVersion: v1
   kind: Service
   metadata:
     name: k8s-gpu-management
   spec:
     selector:
       app: k8s-gpu-management  # Pod ë¼ë²¨ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•¨
     ports:
     - port: 8080
       targetPort: 8080
   ```

2. **ë„¤íŠ¸ì›Œí¬ ì •ì±… í™•ì¸**
   ```bash
   # ë„¤íŠ¸ì›Œí¬ ì •ì±…ì´ íŠ¸ë˜í”½ì„ ì°¨ë‹¨í•˜ëŠ”ì§€ í™•ì¸
   kubectl get networkpolicy -n gpu-management
   kubectl describe networkpolicy -n gpu-management
   ```

---

### ğŸ”’ ë¬¸ì œ: Ingress TLS ì¸ì¦ì„œ ì˜¤ë¥˜

#### ì¦ìƒ
- SSL/TLS í•¸ë“œì…°ì´í¬ ì‹¤íŒ¨
- "Certificate not valid" ì˜¤ë¥˜
- HTTPS ì ‘ì† ë¶ˆê°€

#### ì§„ë‹¨ ë°©ë²•
```bash
# ì¸ì¦ì„œ ìƒíƒœ í™•ì¸
kubectl get certificate -n gpu-management
kubectl describe certificate gpu-management-tls -n gpu-management

# Ingress ì„¤ì • í™•ì¸
kubectl get ingress -n gpu-management -o yaml

# ì¸ì¦ì„œ ë§Œë£Œì¼ í™•ì¸
openssl s_client -connect gpu-management.company.com:443 -servername gpu-management.company.com 2>/dev/null | openssl x509 -noout -dates
```

#### í•´ê²° ë°©ë²•
1. **Let's Encrypt ì¸ì¦ì„œ ê°±ì‹ **
   ```bash
   # cert-managerë¥¼ í†µí•œ ì¸ì¦ì„œ ê°±ì‹ 
   kubectl delete certificate gpu-management-tls -n gpu-management
   kubectl apply -f - <<EOF
   apiVersion: cert-manager.io/v1
   kind: Certificate
   metadata:
     name: gpu-management-tls
     namespace: gpu-management
   spec:
     secretName: gpu-management-tls
     issuerRef:
       name: letsencrypt-prod
       kind: ClusterIssuer
     dnsNames:
     - gpu-management.company.com
   EOF
   ```

---

## ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¬¸ì œ

### ğŸ—„ï¸ ë¬¸ì œ: Oracle Database ì—°ê²° ì‹¤íŒ¨

#### ì¦ìƒ
- "TNS:listener does not currently know of service" ì˜¤ë¥˜
- ì—°ê²° íƒ€ì„ì•„ì›ƒ
- ì¸ì¦ ì‹¤íŒ¨

#### ì§„ë‹¨ ë°©ë²•
```bash
# Oracle DB Pod ìƒíƒœ í™•ì¸
kubectl get pods -l app=oracle-db
kubectl logs oracle-db-0 --tail=100

# ë¦¬ìŠ¤ë„ˆ ìƒíƒœ í™•ì¸
kubectl exec -it oracle-db-0 -- lsnrctl status

# TNS ì—°ê²° í…ŒìŠ¤íŠ¸
kubectl exec -it oracle-db-0 -- \
  sqlplus gpu_admin/password@localhost:1521/ORCL
```

#### í•´ê²° ë°©ë²•
1. **Oracle ì„œë¹„ìŠ¤ ì¬ì‹œì‘**
   ```bash
   # Oracle DB ì¬ì‹œì‘
   kubectl delete pod oracle-db-0
   kubectl wait --for=condition=Ready pod/oracle-db-0 --timeout=300s
   ```

2. **ì—°ê²° ë¬¸ìì—´ ìˆ˜ì •**
   ```yaml
   spring:
     datasource:
       url: jdbc:oracle:thin:@oracle-db.default.svc.cluster.local:1521:ORCL
       # ë˜ëŠ” ì„œë¹„ìŠ¤ ì´ë¦„ í˜•ì‹ìœ¼ë¡œ:
       # url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=oracle-db.default.svc.cluster.local)(PORT=1521))(CONNECT_DATA=(SERVICE_NAME=ORCL)))
   ```

---

### ğŸ“Š ë¬¸ì œ: ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ì €í•˜

#### ì¦ìƒ
- ì¿¼ë¦¬ ì‘ë‹µ ì‹œê°„ ì¦ê°€
- ì—°ê²° í’€ ê³ ê°ˆ ê²½ê³ 
- ë°ë“œë½ ë°œìƒ

#### ì§„ë‹¨ ë°©ë²•
```bash
# Oracle DB ì„±ëŠ¥ í†µê³„
kubectl exec -it oracle-db-0 -- sqlplus gpu_admin/password@localhost:1521/ORCL <<EOF
SELECT name, value FROM v\$sysstat WHERE name IN ('execute count', 'parse count (total)', 'sorts (memory)', 'sorts (disk)');
SELECT sql_text, elapsed_time, executions FROM v\$sql WHERE elapsed_time > 1000000 ORDER BY elapsed_time DESC FETCH FIRST 10 ROWS ONLY;
EOF
```

#### í•´ê²° ë°©ë²•
1. **ì¸ë±ìŠ¤ ìµœì í™”**
   ```sql
   -- ë©”íŠ¸ë¦­ í…Œì´ë¸” ì¸ë±ìŠ¤
   CREATE INDEX idx_gpu_metrics_device_time 
   ON gpu_usage_metrics(device_id, timestamp) PARALLEL 4;
   
   CREATE INDEX idx_gpu_metrics_timestamp 
   ON gpu_usage_metrics(timestamp) PARALLEL 4;
   
   -- í• ë‹¹ í…Œì´ë¸” ì¸ë±ìŠ¤
   CREATE INDEX idx_allocations_status_time 
   ON gpu_allocations(status, allocation_time) PARALLEL 4;
   
   -- í†µê³„ ì •ë³´ ê°±ì‹ 
   EXEC DBMS_STATS.GATHER_TABLE_STATS('GPU_ADMIN', 'GPU_USAGE_METRICS');
   ```

2. **ì—°ê²° í’€ íŠœë‹**
   ```yaml
   spring:
     datasource:
       hikari:
         maximum-pool-size: 30
         minimum-idle: 15
         connection-timeout: 30000
         idle-timeout: 600000
         max-lifetime: 1800000
         leak-detection-threshold: 60000
   ```

---

## ë³´ì•ˆ ë° ê¶Œí•œ ë¬¸ì œ

### ğŸ” ë¬¸ì œ: RBAC ê¶Œí•œ ë¶€ì¡±

#### ì¦ìƒ
- "Forbidden: cannot get resource" ì˜¤ë¥˜
- Kubernetes API ì ‘ê·¼ ê±°ë¶€
- 401/403 HTTP ìƒíƒœ ì½”ë“œ

#### ì§„ë‹¨ ë°©ë²•
```bash
# í˜„ì¬ ê¶Œí•œ í™•ì¸
kubectl auth can-i get nodes --as=system:serviceaccount:gpu-management:gpu-management
kubectl auth can-i list pods --as=system:serviceaccount:gpu-management:gpu-management

# ServiceAccount í™•ì¸
kubectl get serviceaccount gpu-management -n gpu-management
kubectl get clusterrolebinding | grep gpu-management
```

#### í•´ê²° ë°©ë²•
1. **í•„ìš”í•œ ê¶Œí•œ ì¶”ê°€**
   ```yaml
   apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRole
   metadata:
     name: gpu-management-extended
   rules:
   - apiGroups: [""]
     resources: ["nodes", "pods", "services", "endpoints"]
     verbs: ["get", "list", "watch"]
   - apiGroups: ["apps"]
     resources: ["deployments", "daemonsets"]
     verbs: ["get", "list", "watch"]
   - apiGroups: ["metrics.k8s.io"]
     resources: ["nodes", "pods"]
     verbs: ["get", "list"]
   ---
   apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRoleBinding
   metadata:
     name: gpu-management-extended
   roleRef:
     apiGroup: rbac.authorization.k8s.io
     kind: ClusterRole
     name: gpu-management-extended
   subjects:
   - kind: ServiceAccount
     name: gpu-management
     namespace: gpu-management
   ```

---

### ğŸ”‘ ë¬¸ì œ: Secret ë° ConfigMap ì ‘ê·¼ ì˜¤ë¥˜

#### ì¦ìƒ
- í™˜ê²½ ë³€ìˆ˜ ê°’ ëˆ„ë½
- "Could not resolve placeholder" ì˜¤ë¥˜
- ì„¤ì • ë¡œë“œ ì‹¤íŒ¨

#### ì§„ë‹¨ ë°©ë²•
```bash
# Secret ì¡´ì¬ í™•ì¸
kubectl get secret gpu-management-secrets -n gpu-management

# ConfigMap í™•ì¸
kubectl get configmap gpu-management-config -n gpu-management

# Podì—ì„œ ë§ˆìš´íŠ¸ëœ Secret í™•ì¸
kubectl exec -it deployment/k8s-gpu-management -n gpu-management -- \
  env | grep DB_PASSWORD
```

#### í•´ê²° ë°©ë²•
1. **Secret ìƒì„± ë° ë§ˆìš´íŠ¸**
   ```bash
   # Secret ìƒì„±
   kubectl create secret generic gpu-management-secrets \
     --from-literal=db-password=your-password \
     --from-literal=slack-webhook-url=your-webhook-url \
     -n gpu-management
   ```

   ```yaml
   # Deploymentì—ì„œ Secret ì‚¬ìš©
   env:
   - name: DB_PASSWORD
     valueFrom:
       secretKeyRef:
         name: gpu-management-secrets
         key: db-password
   ```

---

## ì¼ë°˜ì ì¸ ì§„ë‹¨ ë° ë³µêµ¬ ëª…ë ¹ì–´

### ğŸ” ì‹œìŠ¤í…œ ì „ì²´ ìƒíƒœ í™•ì¸

```bash
#!/bin/bash
# ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸

echo "=== Pod ìƒíƒœ ==="
kubectl get pods -n gpu-management -o wide

echo "=== ì„œë¹„ìŠ¤ ìƒíƒœ ==="
kubectl get svc,ep -n gpu-management

echo "=== ìµœê·¼ ì´ë²¤íŠ¸ ==="
kubectl get events -n gpu-management --sort-by='.lastTimestamp' | tail -10

echo "=== ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ==="
kubectl top pods -n gpu-management
kubectl top nodes

echo "=== GPU ì¥ë¹„ ìƒíƒœ ==="
curl -s http://localhost:8080/k8s-monitor/api/v1/gpu/devices | \
  jq '.data[] | {deviceId, deviceStatus, currentTempC, currentUtilization}'

echo "=== í™œì„± í• ë‹¹ ==="
curl -s http://localhost:8080/k8s-monitor/api/v1/gpu/allocations | \
  jq '.data[] | select(.status == "ALLOCATED") | {allocationId, podName, allocationTime}'

echo "=== ì• í”Œë¦¬ì¼€ì´ì…˜ í—¬ìŠ¤ ==="
curl -s http://localhost:8080/k8s-monitor/actuator/health | jq
```

### ğŸš¨ ê¸´ê¸‰ ë³µêµ¬ ì ˆì°¨

```bash
#!/bin/bash
# ê¸´ê¸‰ ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸

echo "1. ì„œë¹„ìŠ¤ ì¬ì‹œì‘..."
kubectl rollout restart deployment/k8s-gpu-management -n gpu-management

echo "2. ëŒ€ê¸° ì¤‘..."
kubectl rollout status deployment/k8s-gpu-management -n gpu-management --timeout=300s

echo "3. ë§Œë£Œëœ í• ë‹¹ ì •ë¦¬..."
curl -X POST http://localhost:8080/k8s-monitor/api/v1/gpu/allocations/cleanup

echo "4. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¬ì‹œì‘..."
curl -X POST http://localhost:8080/k8s-monitor/api/v1/gpu/metrics/collection/restart

echo "5. í—¬ìŠ¤ ì²´í¬..."
curl -s http://localhost:8080/k8s-monitor/actuator/health | jq '.status'

echo "ë³µêµ¬ ì™„ë£Œ!"
```

### ğŸ“‹ ì§€ì› ì •ë³´ ìˆ˜ì§‘

```bash
#!/bin/bash
# ì§€ì› ìš”ì²­ì„ ìœ„í•œ ì •ë³´ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸

NAMESPACE="gpu-management"
OUTPUT_DIR="support-bundle-$(date +%Y%m%d_%H%M%S)"

mkdir -p "$OUTPUT_DIR"

echo "ì§€ì› ì •ë³´ ìˆ˜ì§‘ ì¤‘..."

# ê¸°ë³¸ ì •ë³´
kubectl get pods -n $NAMESPACE -o wide > "$OUTPUT_DIR/pods.txt"
kubectl get svc,ep -n $NAMESPACE > "$OUTPUT_DIR/services.txt"
kubectl get events -n $NAMESPACE --sort-by='.lastTimestamp' > "$OUTPUT_DIR/events.txt"

# ë¡œê·¸ ìˆ˜ì§‘
kubectl logs deployment/k8s-gpu-management -n $NAMESPACE --tail=2000 > "$OUTPUT_DIR/app-logs.txt"

# ì„¤ì • ì •ë³´
kubectl get configmap -n $NAMESPACE -o yaml > "$OUTPUT_DIR/configmaps.yaml"
kubectl describe deployment k8s-gpu-management -n $NAMESPACE > "$OUTPUT_DIR/deployment-desc.txt"

# GPU ìƒíƒœ ì •ë³´
curl -s http://localhost:8080/k8s-monitor/api/v1/gpu/overview > "$OUTPUT_DIR/gpu-overview.json"
curl -s http://localhost:8080/k8s-monitor/api/v1/gpu/devices > "$OUTPUT_DIR/gpu-devices.json"
curl -s http://localhost:8080/k8s-monitor/api/v1/gpu/allocations > "$OUTPUT_DIR/gpu-allocations.json"

# ë©”íŠ¸ë¦­ ì •ë³´
curl -s http://localhost:8080/k8s-monitor/actuator/prometheus > "$OUTPUT_DIR/prometheus-metrics.txt"
curl -s http://localhost:8080/k8s-monitor/actuator/health > "$OUTPUT_DIR/health.json"

# ì‹œìŠ¤í…œ ì •ë³´
kubectl top pods -n $NAMESPACE > "$OUTPUT_DIR/resource-usage.txt"
kubectl top nodes > "$OUTPUT_DIR/node-usage.txt"

# ì••ì¶•
tar -czf "$OUTPUT_DIR.tar.gz" "$OUTPUT_DIR"
echo "ì§€ì› ì •ë³´ê°€ $OUTPUT_DIR.tar.gz íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
```

---

## ğŸ†˜ ì§€ì› ë° ì—ìŠ¤ì»¬ë ˆì´ì…˜

### ì—°ë½ì²˜ ì •ë³´
- **ê¸°ìˆ  ì§€ì›**: gpu-support@company.com
- **ê¸´ê¸‰ ì—°ë½ì²˜**: +82-10-xxxx-xxxx  
- **Slack ì±„ë„**: #gpu-management-support
- **GitHub Issues**: https://github.com/company/k8s-gpu-management/issues

### ì§€ì› ìš”ì²­ ì‹œ í¬í•¨í•  ì •ë³´
1. ë°œìƒ ì‹œê°„ ë° ê¸°ê°„
2. ì˜¤ë¥˜ ë©”ì‹œì§€ ì „ë¬¸
3. ì¬í˜„ ë‹¨ê³„
4. ì‹œìŠ¤í…œ í™˜ê²½ ì •ë³´
5. ì§€ì› ë²ˆë“¤ íŒŒì¼ (`support-bundle.tar.gz`)

ì´ ë¬¸ì œ í•´ê²° ê°€ì´ë“œë¥¼ í†µí•´ ëŒ€ë¶€ë¶„ì˜ ì¼ë°˜ì ì¸ ë¬¸ì œë“¤ì„ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ë„ì›€ì´ í•„ìš”í•œ ê²½ìš° ì–¸ì œë“ ì§€ ì§€ì›íŒ€ì— ì—°ë½í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ğŸš€